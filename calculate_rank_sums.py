from scipy.stats import ranksums, wilcoxon
import pandas as pd
import os

baseline_results_array = [[0.6357615894039735, 0.6357615894039735, 0.6357615894039735, 0.5960264900662252, 0.6158940397350994, 0.6423841059602649, 0.609271523178808, 0.6291390728476821, 0.6026490066225165, 0.6357615894039735], [0.6134683098591549, 0.642067392067392, 0.595593461265103, 0.6080962416578855, 0.6181578947368421, 0.5864937388193202, 0.6016146016146016, 0.5881307746979388, 0.5951210951210951, 0.6071428571428571], [0.7692147034252297, 0.7350464576074333, 0.7053435114503817, 0.7254578754578754, 0.7209645669291338, 0.7695094760312151, 0.7541703248463565, 0.6977671451355663, 0.7263993316624895, 0.7977941176470589], [0.561903254734399, 0.5985013294657965, 0.5560010692328254, 0.5416728865004727, 0.5664356435643564, 0.5333104395604396, 0.5360137492838914, 0.5447889750215331, 0.531055900621118, 0.5497424776362158], [0.7692147034252297, 0.7350464576074331, 0.7053435114503817, 0.7254578754578755, 0.7209645669291338, 0.7695094760312152, 0.7541703248463565, 0.6977671451355661, 0.7263993316624896, 0.7977941176470589]]

proposed_results_array = [[0.9139072847682119, 0.8675496688741722, 0.8940397350993378, 0.9072847682119205, 0.8940397350993378, 0.9470198675496688, 0.9337748344370861, 0.9271523178807947, 0.9271523178807947, 0.9271523178807947], [0.8501564945226917, 0.830813347236705, 0.775462962962963, 0.8299019607843137, 0.8305555555555555, 0.8677621283255086, 0.9127543035993739, 0.8309160305343511, 0.8556298773690079, 0.8216312056737589], [0.6869256474519633, 0.6842334494773519, 0.7270992366412214, 0.7465201465201465, 0.734251968503937, 0.761984392419175, 0.7315627743634767, 0.8456937799043063, 0.7664995822890559, 0.7223039215686274], [0.7356228956228956, 0.7234432234432235, 0.747702589807853, 0.7792397660818713, 0.7694656488549618, 0.8038961038961039, 0.7895763656633221, 0.8380618114458418, 0.8022854422092608, 0.7601444043321299], [0.8471177944862155, 0.8989547038327526, 0.8965648854961832, 0.8384615384615384, 0.8615485564304461, 0.9136008918617614, 0.921422300263389, 0.9222488038277512, 0.9010025062656641, 0.9191176470588235]]

# Todo: Choose the project (options: 'pytorch', 'tensorflow', 'keras', 'incubator-mxnet', 'caffe')
project = 'pytorch'
iterations = 10

out_csv_name = f'./results/{project}_rank-sums.csv'

acc_ranksums = ranksums(proposed_results_array[0], baseline_results_array[0])
prec_ranksums = ranksums(proposed_results_array[1], baseline_results_array[1])
recall_ranksums = ranksums(proposed_results_array[2], baseline_results_array[2])
f1_ranksums = ranksums(proposed_results_array[3], baseline_results_array[3])
auc_ranksums = ranksums(proposed_results_array[4], baseline_results_array[4])

print("=== CNN P-Value ===")
print(f"Accuracy:   {acc_ranksums[1]:.10f}")
print(f"Precision:  {prec_ranksums[1]:.10f}")
print(f"Recall:     {recall_ranksums[1]:.10f}")
print(f"F1-Score:   {f1_ranksums[1]:.10f}")
print(f"AUC:        {auc_ranksums[1]:.10f}")

print("\n=== CNN Statistic ===")
print(f"Accuracy:   {acc_ranksums[0]:.10f}")
print(f"Precision:  {prec_ranksums[0]:.10f}")
print(f"Recall:     {recall_ranksums[0]:.10f}")
print(f"F1-Score:   {f1_ranksums[0]:.10f}")
print(f"AUC:        {auc_ranksums[0]:.10f}")

header_needed = not os.path.isfile(out_csv_name)

df_log = pd.DataFrame(
    {
        'iterations': [iterations],
        'Accuracy': [acc_ranksums],
        'Precision': [prec_ranksums],
        'Recall': [recall_ranksums],
        'F1': [f1_ranksums],
        'AUC': [auc_ranksums],
        'raw_data_baseline': [baseline_results_array],
        'raw_data_proposed': [proposed_results_array],
    }
)

df_log.to_csv(out_csv_name, mode='a', header=header_needed, index=False)
print(f"\nResults have been saved to: {out_csv_name}")
